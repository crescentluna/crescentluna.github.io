<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Archives | 心怀畏惧</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="chen hao&apos;s blog | machine learning | data mining">
<meta property="og:type" content="website">
<meta property="og:title" content="心怀畏惧">
<meta property="og:url" content="http://crescentluna.github.io/archives/page/2/index.html">
<meta property="og:site_name" content="心怀畏惧">
<meta property="og:description" content="chen hao&apos;s blog | machine learning | data mining">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="心怀畏惧">
<meta name="twitter:description" content="chen hao&apos;s blog | machine learning | data mining">
  
    <link rel="alternative" href="/atom.xml" title="心怀畏惧" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F1fc57dc5ccfaeae31f8e295269b6fa04' type='text/javascript'%3E%3C/script%3E"));
</script>


  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-57404093-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->

  <script src="https://cdn1.lncld.net/static/js/av-min-1.2.1.js"></script>
  <script>AV.initialize("57nirzk8g437patyg9434lcvmpkat6e5lu5mixmrwqa8l3ao", "rsqg6iiq58eyeg8c6c6uue48crtwt5quuq5dmjaahfcjlkq8");</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">心怀畏惧</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Do not go gentle into that good night</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">主页</a>
        
          <a class="main-nav-link" href="/archives">所有文章</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="http://www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="crescentluna.github.io">
        </form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-三硬币问题-一个EM算法和Gibbs Sampling的例子" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/07/03/三硬币问题-一个EM算法和Gibbs Sampling的例子/" class="article-date">
  <time datetime="2013-07-02T17:41:26.000Z" itemprop="datePublished">2013-07-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/07/03/三硬币问题-一个EM算法和Gibbs Sampling的例子/">三硬币问题-一个EM算法和Gibbs Sampling的例子</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>讲一个EM算法和Gibbs 抽样的小例子，用于加深理解（变分推断版本请见<a href="http://crescentluna.github.io/2014/12/12/variational-inference-3/">变分推断学习笔记(3)——三硬币问题的变分推断解法</a>）。</p>
<p>题目(引用自参考1）：假设有3枚硬币，分别记做A，B，C。这些硬币正面出现的概率分别是<span class="math inline">\(\pi\)</span>,<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span>。进行如下掷硬币实验：先掷硬币A，根据其结果选出硬币B或C，正面选B，反面选硬币C；然后投掷选重中的硬币，出现正面记作1，反面记作0；独立地重复<span class="math inline">\(n\)</span>次（n=10)，结果为 <span class="math display">\[1111110000\]</span> 我们只能观察投掷硬币的结果，而不知其过程，估计这三个参数<span class="math inline">\(\pi\)</span>,<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span>。</p>
<h1 id="em算法">EM算法</h1>
<p>可以看到投掷硬币时到底选择了B或者C是未知的。我们设隐藏变量Z 来指示来自于哪个硬币，<span class="math inline">\(Z=\{z_1,z_2,\ldots,z_n \}\)</span>，令<span class="math inline">\(\theta=\{\pi,p,q\}\)</span>，观察数据<span class="math inline">\(X=\{x_1,x_2,\ldots,x_n \}\)</span>。</p>
<p>写出生成一个硬币时的概率： <span class="math display">\[\begin{split}P(x|\theta) &amp; =\sum_z P(x,z|\theta)=\sum_z P(z|\pi)P(x|z,\theta) \\&amp; =\pi p^x (1-p)^{1-x}+(1-\pi)q^x(1-q)^{1-x} \\\end{split}\]</span> 有了一个硬币的概率，我们就可以写出所有观察数据的log似然函数： <span class="math display">\[L(\theta|X)=\log P(X|\theta)=\sum^n_{j=1}\log[\pi p^{x_j} (1-p)^{1-{x_j}}+(1-\pi)q^{x_j}(1-q)^{1-{x_j}}]\]</span> 然后求极大似然 <span class="math display">\[\hat{\theta}=\arg \max L(\theta|X)\]</span> 其中<span class="math inline">\(L(\theta|X)=\log P(X|\theta)=\log \sum_Z P(X,Z|\theta)\)</span>。因为log里面带着加和所以这个极大似然是求不出解析解的。
        
          <p class="article-more-link">
            <a href="/2013/07/03/三硬币问题-一个EM算法和Gibbs Sampling的例子/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/07/03/三硬币问题-一个EM算法和Gibbs Sampling的例子/" data-id="cizha1r03001ng0o8dm3ighkf" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/07/03/三硬币问题-一个EM算法和Gibbs Sampling的例子/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/EM/">EM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Gibbs-Sampling/">Gibbs Sampling</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Gibbs Sampling for the UniniTiated-3" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/06/29/Gibbs Sampling for the UniniTiated-3/" class="article-date">
  <time datetime="2013-06-29T04:59:37.000Z" itemprop="datePublished">2013-06-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>►<a class="article-category-link" href="/categories/学术/Gibbs-Sampling笔记/">Gibbs Sampling笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/06/29/Gibbs Sampling for the UniniTiated-3/">《Gibbs Sampling for the UniniTiated》阅读笔记(下)---连续型参数求积分的思考</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>《Gibbs Sampling for the UniniTiated》阅读笔记结构：</p>
<ol style="list-style-type: decimal">
<li> <a href="http://www.crescentmoon.info/?p=504">参数估计方法及Gibbs Sampling简介</a></li>
<li><a href="http://www.crescentmoon.info/?p=525">一个朴素贝叶斯文档模型例子</a><br />
</li>
<li><a href="http://www.crescentmoon.info/?p=548">连续型参数求积分的思考</a>
<hr>
</hr></li>
</ol>
<p>这篇是下篇，讨论中篇联合分布中对参数求积分来简化的问题。</p>
<p>之前存在的一个问题就是为啥我们可以对连续参数<span class="math inline">\(\pi\)</span>求积分消去它，而不能对词分布<span class="math inline">\(\theta_0\)</span>和<span class="math inline">\(\theta_1\)</span>求积分。这个主意看上去很美，但是实际做的时候，你会碰到一大把无法约掉的伽马函数。让我们看看具体的过程。</p>
        
          <p class="article-more-link">
            <a href="/2013/06/29/Gibbs Sampling for the UniniTiated-3/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/06/29/Gibbs Sampling for the UniniTiated-3/" data-id="cizha1r00001fg0o86g54jus3" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/06/29/Gibbs Sampling for the UniniTiated-3/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Gibbs-Sampling/">Gibbs Sampling</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Gibbs Sampling for the UniniTiated-2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/06/29/Gibbs Sampling for the UniniTiated-2/" class="article-date">
  <time datetime="2013-06-29T04:49:12.000Z" itemprop="datePublished">2013-06-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>►<a class="article-category-link" href="/categories/学术/Gibbs-Sampling笔记/">Gibbs Sampling笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/06/29/Gibbs Sampling for the UniniTiated-2/">《Gibbs Sampling for the UniniTiated》阅读笔记(中)---一个朴素贝叶斯文档模型例子</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>《Gibbs Sampling for the UniniTiated》阅读笔记结构：</p>
<ol style="list-style-type: decimal">
<li> <a href="http://www.crescentmoon.info/?p=504">参数估计方法及Gibbs Sampling简介</a></li>
<li><a href="http://www.crescentmoon.info/?p=525">一个朴素贝叶斯文档模型例子</a></li>
<li><a href="http://www.crescentmoon.info/?p=548">连续型参数求积分的思考</a></li>
</ol>
<hr>
</hr>
<p>这篇是中篇，介绍一个非常简单的朴素贝叶斯文档模型生成的例子，用来说明Gibbs Sampler具体是如何构造的。</p>
<h2 id="文档生成的建模过程">文档生成的建模过程</h2>
<p>首先我们有一批文档，文档里面有很多单词，这些单词都是无顺序可交换的（词袋模型），这些文档分成两类，类标签为0或者1。给予一篇未标记的文档<span class="math inline">\(W_j\)</span>，我们要做的工作就是预测文档的类标签是<span class="math inline">\(L_j=0\)</span>还是<span class="math inline">\(L_j=1\)</span>。为了方便起见，我们定了类标签所表示的类<span class="math inline">\(\mathbb{C}_0={W_j|L_j=0}\)</span>和<span class="math inline">\(\mathbb{C}_1={W_j|L_j=1}\)</span>。一般来说预测这种事都是选择最有可能发生的，即找到<span class="math inline">\(W_j\)</span>的后验概率<span class="math inline">\(P(L_j|W_j)\)</span>最大的标签<span class="math inline">\(L_j\)</span>。使用贝叶斯公式 <span class="math display">\[\begin{equation}
\begin{split}
L_j=\arg \max \limits_{L}P(L|W_j)&amp; =\arg \max \limits_{L}\frac{P(W_j|L)P(L)}{P(W_j)}\\&amp; =\arg \max \limits_{L} P(W_j|L)P(L) \\\end{split}
\end{equation}\]</span> 因为分母<span class="math inline">\(P(W_j)\)</span>与<span class="math inline">\(L\)</span>无关所以删去了。 通过贝叶斯公式的转换，我们可以想象这些文档的生成过程。首先，我们选择文档的类标签<span class="math inline">\(L_j\)</span>;假设这个过程是通过投硬币完成的（正面概率为<span class="math inline">\(\pi=P(L_j=1)\)</span> )，正式地来说，就是服从贝努利分布 <span class="math display">\[\begin{equation}L_j \sim Bernoulli(\pi)\end{equation}\]</span> 然后，对于文档上<span class="math inline">\(R_j\)</span>个“词位”中的每一个，我们根据一个概率分布<span class="math inline">\(\theta\)</span>，随机独立地抽样一个词<span class="math inline">\(w_i\)</span>。因为每个类生成词的<span class="math inline">\(\theta\)</span>分布都不同，所以应该有<span class="math inline">\(\theta_1\)</span>和<span class="math inline">\(\theta_2\)</span>，具体地生成词的时候，我们根据文档的标签<span class="math inline">\(L_j\)</span>来决定由哪个类来生成 <span class="math display">\[\begin{equation}
W_j \sim Multinomial(R_j,\theta_{L_j})
\end{equation}\]</span>
        
          <p class="article-more-link">
            <a href="/2013/06/29/Gibbs Sampling for the UniniTiated-2/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/06/29/Gibbs Sampling for the UniniTiated-2/" data-id="cizha1r08001xg0o8m73d06b2" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/06/29/Gibbs Sampling for the UniniTiated-2/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Gibbs-Sampling/">Gibbs Sampling</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Gibbs Sampling for the UniniTiated-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/06/29/Gibbs Sampling for the UniniTiated-1/" class="article-date">
  <time datetime="2013-06-29T00:59:53.000Z" itemprop="datePublished">2013-06-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>►<a class="article-category-link" href="/categories/学术/Gibbs-Sampling笔记/">Gibbs Sampling笔记</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/06/29/Gibbs Sampling for the UniniTiated-1/">《Gibbs Sampling for the UniniTiated》阅读笔记(上)---参数估计方法及Gibbs Sampling简介</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>前一阵子折腾的事儿太多，写了点东西都没有传上来，是我偷懒了- -，下不为例。</p>
<p>这篇文章基本上是来自于《Gibbs Sampling for the UniniTiated》，说是笔记其实和翻译也差不多了。</p>
<p>整个结构分为上中下三部分：</p>
<ol style="list-style-type: decimal">
<li> <a href="http://www.crescentmoon.info/?p=504">参数估计方法及Gibbs Sampling简介</a></li>
<li><a href="http://www.crescentmoon.info/?p=525">一个朴素贝叶斯文档模型例子</a></li>
<li><a href="http://www.crescentmoon.info/?p=548">连续型参数求积分的思考</a></li>
</ol>
<hr>
</hr>
<p>这篇是上部分，介绍基础参数估计和Gibbs Sampling概念。</p>
<h2 id="为什么求积分参数估计方法">为什么求积分—参数估计方法</h2>
<p>很多概率模型的算法并不需要使用积分，只要对概率求和就行了（比如隐马尔科夫链的Baum-Welch算法），那么什么时候用到求积分呢？—— 当为了获得概率密度估计的时候，比如说根据一句话前面部分的文本估计下一个词的概率，根据email的内容估计它是否是垃圾邮件的概率等等。为了估计概率密度，一般有MLE（最大似然估计），MAP（最大后验估计），bayesian estimation（贝叶斯估计）三种方法。</p>
<h3 id="最大似然估计">最大似然估计</h3>
<p>这里举一个例子来讲最大似然估计。假设我们有一个硬币，它扔出正面的概率<span class="math inline">\(\pi\)</span>不确定，我们扔了10次，结果为HHHHTTTTTT（H为正面，T为反面）。利用最大似然估计的话，很容易得到下一次为正面的概率为0.4,因为它估计的是使观察数据产生的概率最大的参数。 <a href="http://7sbo5n.com1.z0.glb.clouddn.com/first.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/first.png" alt="first" /></a></p>
<p>令<span class="math inline">\(\chi=\{HHHHTTTTTT\}\)</span>代表观察到的数据,<span class="math inline">\(y\)</span>为下一次抛硬币可能的结果,估计公式如下: <span class="math display">\[\begin{equation}\begin{split}\tilde{\pi}_{MLE} &amp;=\arg \max \limits_{\pi}P(\chi|\pi) \\P(y|\chi) &amp; \approx \int_{\pi} p(y|\tilde{\pi}_{MLE})P(\pi|\chi) d\pi = p(y|\tilde{\pi}_{MLE})\end{split}\end{equation}\]</span></p>
        
          <p class="article-more-link">
            <a href="/2013/06/29/Gibbs Sampling for the UniniTiated-1/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/06/29/Gibbs Sampling for the UniniTiated-1/" data-id="cizha1qzz001cg0o8ugcko05a" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/06/29/Gibbs Sampling for the UniniTiated-1/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Gibbs-Sampling/">Gibbs Sampling</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/参数估计/">参数估计</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-SyntaxHighlighter支持高亮的语言列表" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/04/11/SyntaxHighlighter支持高亮的语言列表/" class="article-date">
  <time datetime="2013-04-10T23:48:31.000Z" itemprop="datePublished">2013-04-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/杂项/">杂项</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/04/11/SyntaxHighlighter支持高亮的语言列表/">SyntaxHighlighter支持高亮的语言列表</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>SyntaxHighlighter是个WordPress（也支持别的博客）上非常好用的语法高亮插件，但是在该插件的设置里没给出默认支持的高亮语言列表<del>（让你自己去官网上找</del>）。查了一下插件的文件，发现除去官网上所列的以外，还支持latex和matlab：</p>
        
          <p class="article-more-link">
            <a href="/2013/04/11/SyntaxHighlighter支持高亮的语言列表/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/04/11/SyntaxHighlighter支持高亮的语言列表/" data-id="cizha1qzv0011g0o82bduxfba" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/04/11/SyntaxHighlighter支持高亮的语言列表/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/wordpress/">wordpress</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-高斯混合模型的matlab实现（转）" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/04/11/高斯混合模型的matlab实现（转）/" class="article-date">
  <time datetime="2013-04-10T23:20:16.000Z" itemprop="datePublished">2013-04-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/04/11/高斯混合模型的matlab实现（转）/">高斯混合模型的matlab实现（转）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>高斯混合函数实现部分是基本上是转载的的pluskid大神<a href="http://blog.pluskid.org/?p=39">文章里</a>的里的代码，加了一点注释，并根据他给的<a href="http://freemind.pluskid.org/machine-learning/regularized-gaussian-covariance-estimation/#7de08bf962fca45b9699432818b939067d7c7327">方法二</a>解决 covariance 矩阵 singular 的问题。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">varargout</span> = <span class="title">gmm</span><span class="params">(X, K_or_centroids)</span></span></div><div class="line"><span class="comment">% ============================================================</span></div><div class="line"><span class="comment">%转载自http://blog.pluskid.org/?p=39</span></div><div class="line"><span class="comment">% Expectation-Maximization iteration implementation of</span></div><div class="line"><span class="comment">% Gaussian Mixture Model.</span></div><div class="line"><span class="comment">%</span></div><div class="line"><span class="comment">% PX = GMM(X, K_OR_CENTROIDS)</span></div><div class="line"><span class="comment">% [PX MODEL] = GMM(X, K_OR_CENTROIDS)</span></div><div class="line"><span class="comment">%</span></div><div class="line"><span class="comment">%  - X: N-by-D data matrix.%需要注意的是这里的X包括了全部</span></div><div class="line"><span class="comment">%  - K_OR_CENTROIDS: either K indicating the number of</span></div><div class="line"><span class="comment">%       components or a K-by-D matrix indicating the</span></div><div class="line"><span class="comment">%       choosing of the initial K centroids.</span></div><div class="line"><span class="comment">%</span></div><div class="line"><span class="comment">%  - PX: N-by-K matrix indicating the probability of each</span></div><div class="line"><span class="comment">%       component generating each point.</span></div><div class="line"><span class="comment">%  - MODEL: a structure containing the parameters for a GMM:</span></div><div class="line"><span class="comment">%       MODEL.Miu: a K-by-D matrix.</span></div><div class="line"><span class="comment">%       MODEL.Sigma: a D-by-D-by-K matrix.</span></div><div class="line"><span class="comment">%       MODEL.Pi: a 1-by-K vector.</span></div><div class="line"><span class="comment">% ============================================================</span></div><div class="line">    threshold = <span class="number">1e-15</span>;</div><div class="line">    [N, D] = <span class="built_in">size</span>(X);</div><div class="line">    </div><div class="line">    <span class="keyword">if</span> <span class="built_in">isscalar</span>(K_or_centroids)</div><div class="line">        K = K_or_centroids;</div><div class="line">        <span class="comment">% randomly pick centroids</span></div><div class="line">        rndp = randperm(N);</div><div class="line">        centroids = X(rndp(<span class="number">1</span>:K),:);</div><div class="line">    <span class="keyword">else</span></div><div class="line">        K = <span class="built_in">size</span>(K_or_centroids, <span class="number">1</span>);</div><div class="line">        centroids = K_or_centroids;</div><div class="line">    <span class="keyword">end</span></div><div class="line">    </div><div class="line">    <span class="comment">% initial values</span></div><div class="line">    [pMiu pPi pSigma] = init_params();</div><div class="line">        </div><div class="line">    Lprev = -<span class="built_in">inf</span>;</div><div class="line">    <span class="keyword">while</span> true</div><div class="line">        Px = calc_prob();<span class="comment">%计算N(x|mu,sigma)</span></div><div class="line">        </div><div class="line">        <span class="comment">% new value for pGamma</span></div><div class="line">        pGamma = Px .* <span class="built_in">repmat</span>(pPi, N, <span class="number">1</span>);<span class="comment">%估计 gamma 是个N*K的矩阵</span></div><div class="line">        pGamma = pGamma ./ <span class="built_in">repmat</span>(sum(pGamma, <span class="number">2</span>), <span class="number">1</span>, K);<span class="comment">%对矩阵的理解真是出神入化,</span></div><div class="line">   </div><div class="line">        <span class="comment">% new value for parameters of each Component</span></div><div class="line">        Nk = sum(pGamma, <span class="number">1</span>);<span class="comment">%N_K</span></div><div class="line">        pMiu = <span class="built_in">diag</span>(<span class="number">1.</span>/Nk) * pGamma' * X;          <span class="comment">%数字 *( K-by-N * N-by-D)加个括号有助理解</span></div><div class="line">        pPi = Nk/N;</div><div class="line">        <span class="keyword">for</span> kk = <span class="number">1</span>:K</div><div class="line">            Xshift = X-<span class="built_in">repmat</span>(pMiu(kk, : ), N, <span class="number">1</span>);<span class="comment">%x-u</span></div><div class="line">            pSigma(:, :, kk) = (Xshift' * ...</div><div class="line">                (<span class="built_in">diag</span>(pGamma(:, kk)) * Xshift)) / Nk(kk);<span class="comment">%更新sigma</span></div><div class="line">   </div><div class="line">             <span class="keyword">end</span></div><div class="line">        <span class="comment">% check for convergence</span></div><div class="line">        L = sum(<span class="built_in">log</span>(Px*pPi'));</div><div class="line">        <span class="keyword">if</span> L-Lprev &lt; threshold</div><div class="line">            <span class="keyword">break</span>;</div><div class="line">        <span class="keyword">end</span></div><div class="line">        Lprev = L;</div><div class="line">    <span class="keyword">end</span></div><div class="line">    </div><div class="line">    <span class="keyword">if</span> nargout == <span class="number">1</span></div><div class="line">        varargout = &#123;Px&#125;;</div><div class="line">    <span class="keyword">else</span></div><div class="line">        model = [];</div><div class="line">        model.Miu = pMiu;</div><div class="line">        model.Sigma = pSigma;</div><div class="line">        model.Pi = pPi;</div><div class="line">        varargout = &#123;pGamma, model&#125;;<span class="comment">%注意！！！！！这里和大神代码不同，他返回的是px，而我是 pGamma</span></div><div class="line">    <span class="keyword">end</span></div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">function</span> <span class="params">[pMiu pPi pSigma]</span> = <span class="title">init_params</span><span class="params">()</span>%初始化参数</span></div><div class="line">        pMiu = centroids;<span class="comment">% K-by-D matrix</span></div><div class="line">        pPi = <span class="built_in">zeros</span>(<span class="number">1</span>, K);<span class="comment">%1-by-K matrix</span></div><div class="line">        pSigma = <span class="built_in">zeros</span>(D, D, K);<span class="comment">%</span></div><div class="line">        </div><div class="line">        <span class="comment">% hard assign x to each centroids</span></div><div class="line">        distmat = <span class="built_in">repmat</span>(sum(X.*X, <span class="number">2</span>), <span class="number">1</span>, K) + ... <span class="comment">% X is a N-by-D data matrix.</span></div><div class="line">            <span class="built_in">repmat</span>(sum(pMiu.*pMiu, <span class="number">2</span>)', N, <span class="number">1</span>) - ...<span class="comment">% X-&gt;K列 U-&gt;N行 XU^T is N-by-K</span></div><div class="line">            <span class="number">2</span>*X*pMiu';<span class="comment">%计算每个点到K个中心的距离</span></div><div class="line">        [~, labels] = min(distmat, [], <span class="number">2</span>);<span class="comment">%找到离X最近的pMiu，[C,I] labels代表这个最小值是从那列选出来的</span></div><div class="line">    </div><div class="line">        <span class="keyword">for</span> k=<span class="number">1</span>:K</div><div class="line">            Xk = X(labels == k, : );<span class="comment">% Xk是所有被归到K类的X向量构成的矩阵</span></div><div class="line">            pPi(k) = <span class="built_in">size</span>(Xk, <span class="number">1</span>)/N;<span class="comment">% 数一数几个归到K类的</span></div><div class="line">            pSigma(:, :, k) = cov(Xk); <span class="comment">%计算协方差矩阵，D-by-D matrix,最小方差无偏估计</span></div><div class="line">        <span class="keyword">end</span></div><div class="line">    <span class="keyword">end</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">function</span> <span class="title">Px</span> = <span class="title">calc_prob</span><span class="params">()</span></span></div><div class="line">        Px = <span class="built_in">zeros</span>(N, K);</div><div class="line">        <span class="keyword">for</span> k = <span class="number">1</span>:K</div><div class="line">            Xshift = X-<span class="built_in">repmat</span>(pMiu(k, : ), N, <span class="number">1</span>);<span class="comment">%x-u</span></div><div class="line">            lemda=<span class="number">1e-5</span>;</div><div class="line">            conv=pSigma(:, :, k)+lemda*<span class="built_in">diag</span>(<span class="built_in">diag</span>(<span class="built_in">ones</span>(D)));<span class="comment">%这里处理singular问题，为协方差矩阵加上一个很小lemda*I</span></div><div class="line">            inv_pSigma = inv(conv);<span class="comment">%协方差的逆</span></div><div class="line">            tmp = sum((Xshift*inv_pSigma) .* Xshift, <span class="number">2</span>);<span class="comment">%(X-U_k)sigma.*(X-U_k),tmp是个N*1的向量</span></div><div class="line">            coef = (<span class="number">2</span>*<span class="built_in">pi</span>)^(-D/<span class="number">2</span>) * <span class="built_in">sqrt</span>(det(inv_pSigma));<span class="comment">%前面的参数</span></div><div class="line">            Px(:, k) = coef * <span class="built_in">exp</span>(<span class="number">-0.5</span>*tmp);<span class="comment">%把数据点 x 带入到 Gaussian model 里得到的值</span></div><div class="line">        <span class="keyword">end</span></div><div class="line">    <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"><span class="comment">%repmat 通过拓展向量到矩阵</span></div><div class="line"><span class="comment">%inv 求逆</span></div><div class="line"><span class="comment">%min 求矩阵最小值，可以返回标签</span></div><div class="line"><span class="comment">%X(labels == k, : ) 对行做筛选</span></div><div class="line"><span class="comment">% size(Xk, 1) 求矩阵的长或宽</span></div><div class="line"><span class="comment">%scatter 对二维向量绘图</span></div></pre></td></tr></table></figure>
<p><span style="color: #ff0000;">注意：</span></p>
<p>pluskid大神这里最后返回的是px，我觉得非常奇怪，因为PRML里对点做hard assignment时是根据后验概率来判别的。于是我在大神博客上问了一下，他的解释是最大似然和最大后验的区别，前者是挑x被各个模型产生的概率最大的那个，而后者加上了先验知识，各有道理。一句话就茅塞顿开，真大神也~
        
          <p class="article-more-link">
            <a href="/2013/04/11/高斯混合模型的matlab实现（转）/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/04/11/高斯混合模型的matlab实现（转）/" data-id="cizha1qzw0016g0o8vyxnv0zy" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/04/11/高斯混合模型的matlab实现（转）/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/matlab/">matlab</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/高斯混合模型/">高斯混合模型</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-高斯混合模型参数估计详细推导过程" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/04/02/高斯混合模型参数估计详细推导过程/" class="article-date">
  <time datetime="2013-04-02T03:44:10.000Z" itemprop="datePublished">2013-04-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/04/02/高斯混合模型参数估计详细推导过程/">高斯混合模型参数估计详细推导过程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>已知多元高斯分布的公式: <span class="math display">\[N(x|\mu,\Sigma)=\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))\]</span> 其中<span class="math inline">\(D\)</span>为维度，<span class="math inline">\(x\)</span>和<span class="math inline">\(\mu\)</span>均为<span class="math inline">\(D\)</span>维向量，协方差<span class="math inline">\(\Sigma\)</span>为D维矩阵。我们求得后验概率： <span class="math display">\[w^{(i)}_j=Q_i(Z^{i}=j)=P(z^{(i)}=j|x^{(i)};\phi,\mu,\Sigma)\]</span> 在E步，<span class="math inline">\(w^{(i)}_j\)</span>是一个固定值，然后我们用它来估计似然函数<span class="math inline">\(L(X,Z;\theta)\)</span>(这里<span class="math inline">\(\theta=(\phi,\mu,\Sigma)\)</span>)在分布<span class="math inline">\(Z\sim P(Z|X;\theta)\)</span>上的期望<span class="math inline">\(E_{Z|X,\theta_t}[L(X,Z;\theta)]\)</span>（式子1）: <span class="math display">\[\begin{split} &amp; \sum^m_{i=1}\sum_{z^{(i)}} Q_i(z^{(i)})\log{\frac{p(x^{(i)},z^{(i)};\phi,\mu,\Sigma)}{Q_i(z^{(i)})}} \\&amp; =\sum^m_{i=1}\sum^k_{j=1} Q_i(z^{(i)}=j)\log{\frac{p(x^{(i)}|z^{(i)}=j;\mu,\Sigma)p(z^{(i)}=j;\phi)}{Q_i(z^{(i)})}} \\&amp; =\sum^m_{i=1}\sum^k_{j=1} w^{(i)}_j\log{\frac{\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\exp(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j))\cdot\phi_j}{ w^{(i)}_j}} \\\end{split}\]</span> 由于分母<span class="math inline">\(w^{(i)}_j\)</span>在取对数之后是常数，与参数无关，求导时自然会变成0，所以我们写公式的时候为了简便舍去分母。
        
          <p class="article-more-link">
            <a href="/2013/04/02/高斯混合模型参数估计详细推导过程/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/04/02/高斯混合模型参数估计详细推导过程/" data-id="cizha1qzv0014g0o81dj119w9" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/04/02/高斯混合模型参数估计详细推导过程/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/EM/">EM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/高斯混合模型/">高斯混合模型</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Introdcution of Community Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/03/26/Introdcution of Community Detection/" class="article-date">
  <time datetime="2013-03-26T00:48:14.000Z" itemprop="datePublished">2013-03-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/03/26/Introdcution of Community Detection/">社区发现及其发展方向简介（未完）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="社区发现简介">1. 社区发现简介</h2>
<p>社区，从直观上来看，是指网络中的一些密集群体，每个社区内部的结点间的联系相对紧密，但是各个社区之间的连接相对来说却比较稀疏（图1，当然社区的定义不止有这一种）。这样的社区现象被研究已经很多年了，最早期的记录甚至来自于80年前。</p>
<p><a href="http://7sbo5n.com1.z0.glb.clouddn.com/aaa.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/aaa.png" alt="aaa" /></a></p>
<p>比较经典的社区研究案例包括对空手道俱乐部(karate club),科学家合作网络(Collaboration network) 和斑马群体(zebras) 的社交行为研究等（见图2），其中著名的空手道俱乐部社区已经成为通常检验社区发现算法效果的标准(benchmark)之一。</p>
        
          <p class="article-more-link">
            <a href="/2013/03/26/Introdcution of Community Detection/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/03/26/Introdcution of Community Detection/" data-id="cizha1qzx0019g0o8v302nl6p" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/03/26/Introdcution of Community Detection/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/社区发现/">社区发现</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Parameter estimation for text analysis" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/03/12/Parameter estimation for text analysis/" class="article-date">
  <time datetime="2013-03-11T18:20:25.000Z" itemprop="datePublished">2013-03-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/03/12/Parameter estimation for text analysis/">LDA学习笔记---来自《Parameter estimation for text analysis》</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span style="color: #ff0000;">2013年10月10日更新。</span></p>
<p>LDA的概率图如下图1所示：<a href="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094645.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094645.png" alt="QQ截图20130312094645" /></a></p>
<p>参数的意思如图2所示：</p>
<p><a href="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094711.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094711.png" alt="QQ截图20130312094711" /></a> 根据模型，文章m的第n个词t是这样生成的：先从文章m的doc-topic分布中生成一个topic编号<span class="math inline">\(z_{m,n}\)</span>，在根据编号第<span class="math inline">\(z_{m,n}\)</span>个的topic-word分布中生成这个词，总够有<span class="math inline">\(K\)</span>个topic，所以总的概率为： <span class="math display">\[ p(w_{m,n}=t|\vec{\theta}_m,\underline{\Phi})=\sum^K_{k=1}p(w_{m,n}=t|\vec{\phi}_k)p(z_{m,n}=k|\vec{\theta}_m)\]</span> 如果我们写出这篇文章的complete-data的联合分布（<span style="color: #ff0000;">意思就是所以变量都已知的情况下</span>），那么式子就是这样的：</p>
<p><a href="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094748.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094748.png" alt="QQ截图20130312094748" /></a></p>
<p>通过对<span class="math inline">\(\vec{\vartheta_m}\)</span>（doc-topic分布）和<span class="math inline">\(\underline{\Phi}\)</span>（topic-word分布）积分以及<span class="math inline">\(z_{m,n}\)</span>求和，我们可以求得<span class="math inline">\(\vec{w_m}\)</span>的边缘分布：</p>
<p><a href="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094757.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094757.png" alt="QQ截图20130312094757" /></a></p>
<p>(<span style="color: #ff0000;">实际上这个边缘分布是求不出来的</span>，因为<span class="math inline">\(z_{m,n}\)</span>是隐藏变量，从而导致<span class="math inline">\(\underline{\vartheta}\)</span>与<span class="math inline">\(\underline{\Phi}\)</span>存在耦合现象，无法积分得到。要注意联合分布和边缘分布对Z乘积与加和的区别）</p>
<p>因为一个语料库有很多篇文章，而且文章之间都是相互独立的，所以整个语料库的似然为 <span class="math display">\[ p(\mathcal{W}|\vec{\alpha},\vec{\beta})=\prod^{M}_{m=1}p(\vec{w_m}|\vec{\alpha},\vec{\beta})\]</span></p>
<p>虽然LDA（latent Dirichlet allocation)是个相对简单的模型，对它直接推断一般也是不可行的，所以我们要采用近似推断的方法，比如Gibbs sampling。</p>
        
          <p class="article-more-link">
            <a href="/2013/03/12/Parameter estimation for text analysis/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/03/12/Parameter estimation for text analysis/" data-id="cizha1qzu000zg0o840tmuepd" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/03/12/Parameter estimation for text analysis/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LDA/">LDA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Monty Hall problem" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/03/01/Monty Hall problem/" class="article-date">
  <time datetime="2013-03-01T05:17:04.000Z" itemprop="datePublished">2013-03-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/杂项/">杂项</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/03/01/Monty Hall problem/">有趣的三门问题（蒙提霍尔问题）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>三门问题（Monty Hall problem），是一个源自博弈论的数学游戏问题，大致出自美国的电视游戏节目Let’s Make a Deal。问题的名字来自该节目的主持人蒙提·霍尔（Monty Hall）。问题非常的有意思^_^，给出叙述如下：</p>
<p>在三扇门中的某扇门以后有一个奖品，选中这扇门就能拿到门后的奖品。你选定了一扇门，具体地说，假设你选择了1号门。这时候主持人蒙提·霍尔会打开剩下两扇门的其中一扇，你看到门后没有奖品。这时候他给你一个机会选择要不要换另外一扇没有打开的门。你是选择换还是不换呢？</p>
<p>答：因为我之前就选了，换或者不换机会都是均等的，所以换不换无关紧要╮(╯▽╰)╭。 ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ 真的是这样么？仔细分析一下，游戏过程中你做了2个操作： 第一，你选择了一扇门。第二，你选择了换门或者不换。 定义事件<span class="math inline">\(A\)</span>为你第一次就选中奖品。 定义事件<span class="math inline">\(B\)</span>为你换门选中奖品。 那么<span class="math inline">\(A^c\)</span>为集合A的余集，即第一次没有选中奖品。同理，<span class="math inline">\(B^c\)</span>为换门没有选中奖品。整个游戏过程中，<span class="math inline">\(A\)</span>或<span class="math inline">\(A^c\)</span>先发生，<span class="math inline">\(B\)</span>或<span class="math inline">\(B^c\)</span>再发生。 显而易见的是 <span class="math display">\[P(A)=1/3,P(A^c)=2/3\]</span> 要注意的是，在第一次操作之后，还有一件事——主持人打开了一扇没有奖品的门。值得注意的是，这里主持人的动作是跟你第一次选择有关系的：</p>
<ol style="list-style-type: decimal">
<li><p>如果你一开始就选中了奖品，即事件<span class="math inline">\(A\)</span>发生了，那么他就在剩下的两扇没有奖品的门之间任选一门打开。接下来，如果你选择换门，那么抽中的概率为0，不换抽中的概率为1。 即 <span class="math display">\[P(B|A)=0,P(B^c|A)=1\]</span> 因为事件<span class="math inline">\(B\)</span>或<span class="math inline">\(B^c\)</span>是在事件A发生之后发生的，所以这里的概率是基于事件<span class="math inline">\(A\)</span>的条件概率。</p></li>
<li><p>如果你开始没有选中奖品，即事件<span class="math inline">\(A^c\)</span>发生了，那么他只能打开另一扇没有奖品的门。这时候，如果你选择换门，那么抽中的概率为1，不换抽中的概率为0。 即 <span class="math display">\[P(B|A^c)=1,P(B^c|A^c)=0\]</span> 这里的概率是基于事件<span class="math inline">\(A^c\)</span>的条件概率。</p></li>
</ol>
<p>由上我们可以发现一点，事件<span class="math inline">\(A\)</span>会影响事件<span class="math inline">\(B\)</span>的概率，即事件<span class="math inline">\(A\)</span>和事件<span class="math inline">\(B\)</span>并不是相互独立的。<span class="math inline">\(A^c\)</span>和<span class="math inline">\(B^c\)</span>也是同理。 于是，利用全概率公式，我们可以求得换门选中奖品的概率为 <span class="math display">\[P(B)=P(B|A)P(A)+P(B|A^c)P(A^c)=0*1/3+1*2/3=2/3\]</span> <span class="math display">\[P(B^c)=P(B^c|A)P(A)+P(B^c|A^c)P(A^c)=1*1/3+0*2/3=1/3\]</span> 所以事实上你换门能得到奖品的概率为2/3，是不换门的2倍<del>（懂点数学真好啊）</del>。是不是和直觉不太一样？个人认为，直观上觉得<span class="math inline">\(P(B)=1/2\)</span>的原因是忽略了第一次选择时，通过主持人的动作改变了换门的事件概率这一客观过程。 <span style="color: #ff0000;">2013年7月3日更新</span><br>
从信息论的角度来说，B事件的熵为H(B)，在A事件发生之后B事件的条件熵为H(B|A)，可以证明 <span class="math display">\[H(B) \geq H(B|A) \]</span> 也就是说，在给予了A的信息之后，B的不确定性下降了。</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/03/01/Monty Hall problem/" data-id="cizha1qzt000wg0o8mebztao7" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/03/01/Monty Hall problem/#ds-thread" class="article-comment-link">Comments</a>
      

      
    </footer>
  </div>
  
</article>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/archives/">&laquo; Prev</a><a class="page-number" href="/archives/">1</a><span class="page-number current">2</span><a class="page-number" href="/archives/page/3/">3</a><a class="extend next" rel="next" href="/archives/page/3/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/学术/">学术</a><span class="category-list-count">18</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/学术/Gibbs-Sampling笔记/">Gibbs Sampling笔记</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/学术/变分推断笔记/">变分推断笔记</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂项/">杂项</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/杂项/闲话/">闲话</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/DP/" style="font-size: 13.33px;">DP</a> <a href="/tags/EM/" style="font-size: 20px;">EM</a> <a href="/tags/Gibbs-Sampling/" style="font-size: 20px;">Gibbs Sampling</a> <a href="/tags/Hexo/" style="font-size: 13.33px;">Hexo</a> <a href="/tags/LDA/" style="font-size: 10px;">LDA</a> <a href="/tags/PRML/" style="font-size: 13.33px;">PRML</a> <a href="/tags/Variational-Inference/" style="font-size: 16.67px;">Variational Inference</a> <a href="/tags/kNN/" style="font-size: 10px;">kNN</a> <a href="/tags/matlab/" style="font-size: 10px;">matlab</a> <a href="/tags/tensorflow/" style="font-size: 10px;">tensorflow</a> <a href="/tags/wordpress/" style="font-size: 10px;">wordpress</a> <a href="/tags/二叉树/" style="font-size: 10px;">二叉树</a> <a href="/tags/决策树/" style="font-size: 10px;">决策树</a> <a href="/tags/动态规划/" style="font-size: 10px;">动态规划</a> <a href="/tags/参数估计/" style="font-size: 10px;">参数估计</a> <a href="/tags/多项式分布/" style="font-size: 10px;">多项式分布</a> <a href="/tags/数据挖掘/" style="font-size: 16.67px;">数据挖掘</a> <a href="/tags/机器学习/" style="font-size: 16.67px;">机器学习</a> <a href="/tags/概率图/" style="font-size: 10px;">概率图</a> <a href="/tags/盘子/" style="font-size: 10px;">盘子</a> <a href="/tags/社区发现/" style="font-size: 10px;">社区发现</a> <a href="/tags/背包问题/" style="font-size: 13.33px;">背包问题</a> <a href="/tags/贝叶斯方法/" style="font-size: 10px;">贝叶斯方法</a> <a href="/tags/高斯混合模型/" style="font-size: 16.67px;">高斯混合模型</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/02/">二月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/10/">十月 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/08/">八月 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/07/">七月 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/06/">六月 2013</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/04/">四月 2013</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/03/">三月 2013</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/02/">二月 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/01/">一月 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/12/">十二月 2012</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/10/">十月 2012</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/09/">九月 2012</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">浏览数目</h3>
    <div class="widget">
      <ul class="popularlist">
      </ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">近期文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/02/23/install-tensorflow-with-gpu-support-for-ubuntu/">在Ubuntu上搭建GPU加速的TensorFlow环境</a>
          </li>
        
          <li>
            <a href="/2014/12/12/variational-inference-3/">变分推断学习笔记(3)——三硬币问题的变分推断解法</a>
          </li>
        
          <li>
            <a href="/2014/12/11/popular-widget/">使用LeanCloud平台为Hexo博客添加文章浏览量统计组件</a>
          </li>
        
          <li>
            <a href="/2014/12/11/relocation/">博客迁移小记</a>
          </li>
        
          <li>
            <a href="/2014/02/24/概率图模型简介/">概率图模型简介</a>
          </li>
        
      </ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
  <h3 class="widget-title">最近评论</h3>
  <ul class="widget ds-recent-comments" data-num-items="5" data-show-avatars="0" data-show-title="1" data-show-time="1"></ul>
</div>
<!-- 需要多说的公用代码 -->


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://github.com/xiangming/landscape-plus" target="_blank">landscape-plus主题</a>
          </li>
        
          <li>
            <a href="http://www.smallqiao.com/" target="_blank">小桥流水</a>
          </li>
        
          <li>
            <a href="http://www.ahathinking.com/" target="_blank">勇幸|Thinking</a>
          </li>
        
          <li>
            <a href="http://www.socona.me/" target="_blank">socona的博客</a>
          </li>
        
          <li>
            <a href="http://www.clarkchen.com/" target="_blank">陈曦师兄的博客</a>
          </li>
        
          <li>
            <a href="http://www.fengyafei.com/" target="_blank">小飞的博客</a>
          </li>
        
          <li>
            <a href="http://ariwaranosai.xyz/" target="_blank">今天拒绝负能量!</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Chen Hao<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/xiangming/landscape-plus" target="_blank">Landscape-plus</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">主页</a>
  
    <a href="/archives" class="mobile-nav-link">所有文章</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    
<!-- 多说公共js代码 start -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"crescent"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
<!-- 多说公共js代码 end -->


<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>window._bd_share_config={"common":{},"share":{"bdCustomStyle":"nocss.css"}};with(document)0[(getElementsByTagName("head")[0]||body).appendChild(createElement("script")).src="http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion="+~(-new Date()/36e5)];</script>

<!-- 百度分享 end -->

<script src="//libs.baidu.com/jquery/1.11.1/jquery.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<! -- mathjax config similar to math.stackexchange -->
<! -- add autoNumber settting -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true
                    
}
  
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                  
}
    
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
            for(i=0; i < all.length; i += 1) {
                            all[i].SourceElement().parentNode.className += ' has-jax';
                                    
            }
                
        });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script src="/js/script.js"></script>

<!--page counter part-->
<script>
function addCount (Counter) {
        url=$('.article-date').attr('href').trim();
        title = $('.article-title').text().trim();
       // alert(title);
        var query=new AV.Query(Counter);
        //use url as unique idnetfication
        query.equalTo("url",url);
        query.find({
            success: function(results){
                if(results.length>0)
                {
                    var counter=results[0];
                    counter.fetchWhenSave(true); //get recent result
                    counter.increment("time");
                    counter.save();
                    //alert('find '+title+' and visit time is now '+ counter.get("time"));
                }
                else
                {
                    var newcounter=new Counter();
                    newcounter.set("title",title);
                    newcounter.set("url",url);
                    newcounter.set("time",1);
                    newcounter.save(null,{
                        success: function(newcounter){
                        //alert('New object created');
                        },
                        error: function(newcounter,error){
                        alert('Failed to create');
                        }
                        });
                }
            },
            error: function(error){
                //find null is not a error
                alert('Error:'+error.code+" "+error.message);
            }
        });
}

$(function(){
        var Counter=AV.Object.extend("Counter");
        //only increse visit counting when intering a page
        if ($('.article-title').length == 1)
           addCount(Counter);
        var query=new AV.Query(Counter);
        query.descending("time");
        query.limit(10);
        query.find({
            success: function(results){
                    for(var i=0;i<results.length;i++)    
                    {
                        var counter=results[i];
                        //alert(counter.get("title")+'-'+counter.get("url"));
                        title=counter.get("title");
                        url=counter.get("url");
                        time=counter.get("time");
                        // add to the popularlist widget
                        showcontent=title+" ("+time+")";
                        //notice the "" in href
                        $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                    }
                },
            error: function(error){
                alert("Error:"+error.code+" "+error.message);
            }
            }
        )
        });
</script>


  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>