<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Archives: 2013 | 心怀畏惧</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="chen hao&apos;s blog | machine learning | data mining">
<meta property="og:type" content="website">
<meta property="og:title" content="心怀畏惧">
<meta property="og:url" content="http://crescentluna.github.io/archives/2013/page/2/index.html">
<meta property="og:site_name" content="心怀畏惧">
<meta property="og:description" content="chen hao&apos;s blog | machine learning | data mining">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="心怀畏惧">
<meta name="twitter:description" content="chen hao&apos;s blog | machine learning | data mining">
  
    <link rel="alternative" href="/atom.xml" title="心怀畏惧" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F1fc57dc5ccfaeae31f8e295269b6fa04' type='text/javascript'%3E%3C/script%3E"));
</script>


  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-57404093-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->

  <script src="https://cdn1.lncld.net/static/js/av-min-1.2.1.js"></script>
  <script>AV.initialize("57nirzk8g437patyg9434lcvmpkat6e5lu5mixmrwqa8l3ao", "rsqg6iiq58eyeg8c6c6uue48crtwt5quuq5dmjaahfcjlkq8");</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">心怀畏惧</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Do not go gentle into that good night</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">主页</a>
        
          <a class="main-nav-link" href="/archives">所有文章</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="http://www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="crescentluna.github.io">
        </form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-高斯混合模型的matlab实现（转）" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/04/11/高斯混合模型的matlab实现（转）/" class="article-date">
  <time datetime="2013-04-10T23:20:16.000Z" itemprop="datePublished">2013-04-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/04/11/高斯混合模型的matlab实现（转）/">高斯混合模型的matlab实现（转）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>高斯混合函数实现部分是基本上是转载的的pluskid大神<a href="http://blog.pluskid.org/?p=39">文章里</a>的里的代码，加了一点注释，并根据他给的<a href="http://freemind.pluskid.org/machine-learning/regularized-gaussian-covariance-estimation/#7de08bf962fca45b9699432818b939067d7c7327">方法二</a>解决 covariance 矩阵 singular 的问题。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">varargout</span> = <span class="title">gmm</span><span class="params">(X, K_or_centroids)</span></span></div><div class="line"><span class="comment">% ============================================================</span></div><div class="line"><span class="comment">%转载自http://blog.pluskid.org/?p=39</span></div><div class="line"><span class="comment">% Expectation-Maximization iteration implementation of</span></div><div class="line"><span class="comment">% Gaussian Mixture Model.</span></div><div class="line"><span class="comment">%</span></div><div class="line"><span class="comment">% PX = GMM(X, K_OR_CENTROIDS)</span></div><div class="line"><span class="comment">% [PX MODEL] = GMM(X, K_OR_CENTROIDS)</span></div><div class="line"><span class="comment">%</span></div><div class="line"><span class="comment">%  - X: N-by-D data matrix.%需要注意的是这里的X包括了全部</span></div><div class="line"><span class="comment">%  - K_OR_CENTROIDS: either K indicating the number of</span></div><div class="line"><span class="comment">%       components or a K-by-D matrix indicating the</span></div><div class="line"><span class="comment">%       choosing of the initial K centroids.</span></div><div class="line"><span class="comment">%</span></div><div class="line"><span class="comment">%  - PX: N-by-K matrix indicating the probability of each</span></div><div class="line"><span class="comment">%       component generating each point.</span></div><div class="line"><span class="comment">%  - MODEL: a structure containing the parameters for a GMM:</span></div><div class="line"><span class="comment">%       MODEL.Miu: a K-by-D matrix.</span></div><div class="line"><span class="comment">%       MODEL.Sigma: a D-by-D-by-K matrix.</span></div><div class="line"><span class="comment">%       MODEL.Pi: a 1-by-K vector.</span></div><div class="line"><span class="comment">% ============================================================</span></div><div class="line">    threshold = <span class="number">1e-15</span>;</div><div class="line">    [N, D] = <span class="built_in">size</span>(X);</div><div class="line">    </div><div class="line">    <span class="keyword">if</span> <span class="built_in">isscalar</span>(K_or_centroids)</div><div class="line">        K = K_or_centroids;</div><div class="line">        <span class="comment">% randomly pick centroids</span></div><div class="line">        rndp = randperm(N);</div><div class="line">        centroids = X(rndp(<span class="number">1</span>:K),:);</div><div class="line">    <span class="keyword">else</span></div><div class="line">        K = <span class="built_in">size</span>(K_or_centroids, <span class="number">1</span>);</div><div class="line">        centroids = K_or_centroids;</div><div class="line">    <span class="keyword">end</span></div><div class="line">    </div><div class="line">    <span class="comment">% initial values</span></div><div class="line">    [pMiu pPi pSigma] = init_params();</div><div class="line">        </div><div class="line">    Lprev = -<span class="built_in">inf</span>;</div><div class="line">    <span class="keyword">while</span> true</div><div class="line">        Px = calc_prob();<span class="comment">%计算N(x|mu,sigma)</span></div><div class="line">        </div><div class="line">        <span class="comment">% new value for pGamma</span></div><div class="line">        pGamma = Px .* <span class="built_in">repmat</span>(pPi, N, <span class="number">1</span>);<span class="comment">%估计 gamma 是个N*K的矩阵</span></div><div class="line">        pGamma = pGamma ./ <span class="built_in">repmat</span>(sum(pGamma, <span class="number">2</span>), <span class="number">1</span>, K);<span class="comment">%对矩阵的理解真是出神入化,</span></div><div class="line">   </div><div class="line">        <span class="comment">% new value for parameters of each Component</span></div><div class="line">        Nk = sum(pGamma, <span class="number">1</span>);<span class="comment">%N_K</span></div><div class="line">        pMiu = <span class="built_in">diag</span>(<span class="number">1.</span>/Nk) * pGamma' * X;          <span class="comment">%数字 *( K-by-N * N-by-D)加个括号有助理解</span></div><div class="line">        pPi = Nk/N;</div><div class="line">        <span class="keyword">for</span> kk = <span class="number">1</span>:K</div><div class="line">            Xshift = X-<span class="built_in">repmat</span>(pMiu(kk, : ), N, <span class="number">1</span>);<span class="comment">%x-u</span></div><div class="line">            pSigma(:, :, kk) = (Xshift' * ...</div><div class="line">                (<span class="built_in">diag</span>(pGamma(:, kk)) * Xshift)) / Nk(kk);<span class="comment">%更新sigma</span></div><div class="line">   </div><div class="line">             <span class="keyword">end</span></div><div class="line">        <span class="comment">% check for convergence</span></div><div class="line">        L = sum(<span class="built_in">log</span>(Px*pPi'));</div><div class="line">        <span class="keyword">if</span> L-Lprev &lt; threshold</div><div class="line">            <span class="keyword">break</span>;</div><div class="line">        <span class="keyword">end</span></div><div class="line">        Lprev = L;</div><div class="line">    <span class="keyword">end</span></div><div class="line">    </div><div class="line">    <span class="keyword">if</span> nargout == <span class="number">1</span></div><div class="line">        varargout = &#123;Px&#125;;</div><div class="line">    <span class="keyword">else</span></div><div class="line">        model = [];</div><div class="line">        model.Miu = pMiu;</div><div class="line">        model.Sigma = pSigma;</div><div class="line">        model.Pi = pPi;</div><div class="line">        varargout = &#123;pGamma, model&#125;;<span class="comment">%注意！！！！！这里和大神代码不同，他返回的是px，而我是 pGamma</span></div><div class="line">    <span class="keyword">end</span></div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">function</span> <span class="params">[pMiu pPi pSigma]</span> = <span class="title">init_params</span><span class="params">()</span>%初始化参数</span></div><div class="line">        pMiu = centroids;<span class="comment">% K-by-D matrix</span></div><div class="line">        pPi = <span class="built_in">zeros</span>(<span class="number">1</span>, K);<span class="comment">%1-by-K matrix</span></div><div class="line">        pSigma = <span class="built_in">zeros</span>(D, D, K);<span class="comment">%</span></div><div class="line">        </div><div class="line">        <span class="comment">% hard assign x to each centroids</span></div><div class="line">        distmat = <span class="built_in">repmat</span>(sum(X.*X, <span class="number">2</span>), <span class="number">1</span>, K) + ... <span class="comment">% X is a N-by-D data matrix.</span></div><div class="line">            <span class="built_in">repmat</span>(sum(pMiu.*pMiu, <span class="number">2</span>)', N, <span class="number">1</span>) - ...<span class="comment">% X-&gt;K列 U-&gt;N行 XU^T is N-by-K</span></div><div class="line">            <span class="number">2</span>*X*pMiu';<span class="comment">%计算每个点到K个中心的距离</span></div><div class="line">        [~, labels] = min(distmat, [], <span class="number">2</span>);<span class="comment">%找到离X最近的pMiu，[C,I] labels代表这个最小值是从那列选出来的</span></div><div class="line">    </div><div class="line">        <span class="keyword">for</span> k=<span class="number">1</span>:K</div><div class="line">            Xk = X(labels == k, : );<span class="comment">% Xk是所有被归到K类的X向量构成的矩阵</span></div><div class="line">            pPi(k) = <span class="built_in">size</span>(Xk, <span class="number">1</span>)/N;<span class="comment">% 数一数几个归到K类的</span></div><div class="line">            pSigma(:, :, k) = cov(Xk); <span class="comment">%计算协方差矩阵，D-by-D matrix,最小方差无偏估计</span></div><div class="line">        <span class="keyword">end</span></div><div class="line">    <span class="keyword">end</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">function</span> <span class="title">Px</span> = <span class="title">calc_prob</span><span class="params">()</span></span></div><div class="line">        Px = <span class="built_in">zeros</span>(N, K);</div><div class="line">        <span class="keyword">for</span> k = <span class="number">1</span>:K</div><div class="line">            Xshift = X-<span class="built_in">repmat</span>(pMiu(k, : ), N, <span class="number">1</span>);<span class="comment">%x-u</span></div><div class="line">            lemda=<span class="number">1e-5</span>;</div><div class="line">            conv=pSigma(:, :, k)+lemda*<span class="built_in">diag</span>(<span class="built_in">diag</span>(<span class="built_in">ones</span>(D)));<span class="comment">%这里处理singular问题，为协方差矩阵加上一个很小lemda*I</span></div><div class="line">            inv_pSigma = inv(conv);<span class="comment">%协方差的逆</span></div><div class="line">            tmp = sum((Xshift*inv_pSigma) .* Xshift, <span class="number">2</span>);<span class="comment">%(X-U_k)sigma.*(X-U_k),tmp是个N*1的向量</span></div><div class="line">            coef = (<span class="number">2</span>*<span class="built_in">pi</span>)^(-D/<span class="number">2</span>) * <span class="built_in">sqrt</span>(det(inv_pSigma));<span class="comment">%前面的参数</span></div><div class="line">            Px(:, k) = coef * <span class="built_in">exp</span>(<span class="number">-0.5</span>*tmp);<span class="comment">%把数据点 x 带入到 Gaussian model 里得到的值</span></div><div class="line">        <span class="keyword">end</span></div><div class="line">    <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"><span class="comment">%repmat 通过拓展向量到矩阵</span></div><div class="line"><span class="comment">%inv 求逆</span></div><div class="line"><span class="comment">%min 求矩阵最小值，可以返回标签</span></div><div class="line"><span class="comment">%X(labels == k, : ) 对行做筛选</span></div><div class="line"><span class="comment">% size(Xk, 1) 求矩阵的长或宽</span></div><div class="line"><span class="comment">%scatter 对二维向量绘图</span></div></pre></td></tr></table></figure>
<p><span style="color: #ff0000;">注意：</span></p>
<p>pluskid大神这里最后返回的是px，我觉得非常奇怪，因为PRML里对点做hard assignment时是根据后验概率来判别的。于是我在大神博客上问了一下，他的解释是最大似然和最大后验的区别，前者是挑x被各个模型产生的概率最大的那个，而后者加上了先验知识，各有道理。一句话就茅塞顿开，真大神也~
        
          <p class="article-more-link">
            <a href="/2013/04/11/高斯混合模型的matlab实现（转）/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/04/11/高斯混合模型的matlab实现（转）/" data-id="cizha1qzw0016g0o8vyxnv0zy" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/04/11/高斯混合模型的matlab实现（转）/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/matlab/">matlab</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/高斯混合模型/">高斯混合模型</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-高斯混合模型参数估计详细推导过程" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/04/02/高斯混合模型参数估计详细推导过程/" class="article-date">
  <time datetime="2013-04-02T03:44:10.000Z" itemprop="datePublished">2013-04-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/04/02/高斯混合模型参数估计详细推导过程/">高斯混合模型参数估计详细推导过程</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>已知多元高斯分布的公式: <span class="math display">\[N(x|\mu,\Sigma)=\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))\]</span> 其中<span class="math inline">\(D\)</span>为维度，<span class="math inline">\(x\)</span>和<span class="math inline">\(\mu\)</span>均为<span class="math inline">\(D\)</span>维向量，协方差<span class="math inline">\(\Sigma\)</span>为D维矩阵。我们求得后验概率： <span class="math display">\[w^{(i)}_j=Q_i(Z^{i}=j)=P(z^{(i)}=j|x^{(i)};\phi,\mu,\Sigma)\]</span> 在E步，<span class="math inline">\(w^{(i)}_j\)</span>是一个固定值，然后我们用它来估计似然函数<span class="math inline">\(L(X,Z;\theta)\)</span>(这里<span class="math inline">\(\theta=(\phi,\mu,\Sigma)\)</span>)在分布<span class="math inline">\(Z\sim P(Z|X;\theta)\)</span>上的期望<span class="math inline">\(E_{Z|X,\theta_t}[L(X,Z;\theta)]\)</span>（式子1）: <span class="math display">\[\begin{split} &amp; \sum^m_{i=1}\sum_{z^{(i)}} Q_i(z^{(i)})\log{\frac{p(x^{(i)},z^{(i)};\phi,\mu,\Sigma)}{Q_i(z^{(i)})}} \\&amp; =\sum^m_{i=1}\sum^k_{j=1} Q_i(z^{(i)}=j)\log{\frac{p(x^{(i)}|z^{(i)}=j;\mu,\Sigma)p(z^{(i)}=j;\phi)}{Q_i(z^{(i)})}} \\&amp; =\sum^m_{i=1}\sum^k_{j=1} w^{(i)}_j\log{\frac{\frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\exp(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j))\cdot\phi_j}{ w^{(i)}_j}} \\\end{split}\]</span> 由于分母<span class="math inline">\(w^{(i)}_j\)</span>在取对数之后是常数，与参数无关，求导时自然会变成0，所以我们写公式的时候为了简便舍去分母。
        
          <p class="article-more-link">
            <a href="/2013/04/02/高斯混合模型参数估计详细推导过程/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/04/02/高斯混合模型参数估计详细推导过程/" data-id="cizha1qzv0014g0o81dj119w9" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/04/02/高斯混合模型参数估计详细推导过程/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/EM/">EM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/高斯混合模型/">高斯混合模型</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Introdcution of Community Detection" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/03/26/Introdcution of Community Detection/" class="article-date">
  <time datetime="2013-03-26T00:48:14.000Z" itemprop="datePublished">2013-03-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/03/26/Introdcution of Community Detection/">社区发现及其发展方向简介（未完）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="社区发现简介">1. 社区发现简介</h2>
<p>社区，从直观上来看，是指网络中的一些密集群体，每个社区内部的结点间的联系相对紧密，但是各个社区之间的连接相对来说却比较稀疏（图1，当然社区的定义不止有这一种）。这样的社区现象被研究已经很多年了，最早期的记录甚至来自于80年前。</p>
<p><a href="http://7sbo5n.com1.z0.glb.clouddn.com/aaa.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/aaa.png" alt="aaa" /></a></p>
<p>比较经典的社区研究案例包括对空手道俱乐部(karate club),科学家合作网络(Collaboration network) 和斑马群体(zebras) 的社交行为研究等（见图2），其中著名的空手道俱乐部社区已经成为通常检验社区发现算法效果的标准(benchmark)之一。</p>
        
          <p class="article-more-link">
            <a href="/2013/03/26/Introdcution of Community Detection/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/03/26/Introdcution of Community Detection/" data-id="cizha1qzx0019g0o8v302nl6p" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/03/26/Introdcution of Community Detection/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/社区发现/">社区发现</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Parameter estimation for text analysis" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/03/12/Parameter estimation for text analysis/" class="article-date">
  <time datetime="2013-03-11T18:20:25.000Z" itemprop="datePublished">2013-03-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/03/12/Parameter estimation for text analysis/">LDA学习笔记---来自《Parameter estimation for text analysis》</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span style="color: #ff0000;">2013年10月10日更新。</span></p>
<p>LDA的概率图如下图1所示：<a href="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094645.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094645.png" alt="QQ截图20130312094645" /></a></p>
<p>参数的意思如图2所示：</p>
<p><a href="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094711.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094711.png" alt="QQ截图20130312094711" /></a> 根据模型，文章m的第n个词t是这样生成的：先从文章m的doc-topic分布中生成一个topic编号<span class="math inline">\(z_{m,n}\)</span>，在根据编号第<span class="math inline">\(z_{m,n}\)</span>个的topic-word分布中生成这个词，总够有<span class="math inline">\(K\)</span>个topic，所以总的概率为： <span class="math display">\[ p(w_{m,n}=t|\vec{\theta}_m,\underline{\Phi})=\sum^K_{k=1}p(w_{m,n}=t|\vec{\phi}_k)p(z_{m,n}=k|\vec{\theta}_m)\]</span> 如果我们写出这篇文章的complete-data的联合分布（<span style="color: #ff0000;">意思就是所以变量都已知的情况下</span>），那么式子就是这样的：</p>
<p><a href="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094748.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094748.png" alt="QQ截图20130312094748" /></a></p>
<p>通过对<span class="math inline">\(\vec{\vartheta_m}\)</span>（doc-topic分布）和<span class="math inline">\(\underline{\Phi}\)</span>（topic-word分布）积分以及<span class="math inline">\(z_{m,n}\)</span>求和，我们可以求得<span class="math inline">\(\vec{w_m}\)</span>的边缘分布：</p>
<p><a href="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094757.png"><img src="http://7sbo5n.com1.z0.glb.clouddn.com/QQ截图20130312094757.png" alt="QQ截图20130312094757" /></a></p>
<p>(<span style="color: #ff0000;">实际上这个边缘分布是求不出来的</span>，因为<span class="math inline">\(z_{m,n}\)</span>是隐藏变量，从而导致<span class="math inline">\(\underline{\vartheta}\)</span>与<span class="math inline">\(\underline{\Phi}\)</span>存在耦合现象，无法积分得到。要注意联合分布和边缘分布对Z乘积与加和的区别）</p>
<p>因为一个语料库有很多篇文章，而且文章之间都是相互独立的，所以整个语料库的似然为 <span class="math display">\[ p(\mathcal{W}|\vec{\alpha},\vec{\beta})=\prod^{M}_{m=1}p(\vec{w_m}|\vec{\alpha},\vec{\beta})\]</span></p>
<p>虽然LDA（latent Dirichlet allocation)是个相对简单的模型，对它直接推断一般也是不可行的，所以我们要采用近似推断的方法，比如Gibbs sampling。</p>
        
          <p class="article-more-link">
            <a href="/2013/03/12/Parameter estimation for text analysis/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/03/12/Parameter estimation for text analysis/" data-id="cizha1qzu000zg0o840tmuepd" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/03/12/Parameter estimation for text analysis/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LDA/">LDA</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-Monty Hall problem" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/03/01/Monty Hall problem/" class="article-date">
  <time datetime="2013-03-01T05:17:04.000Z" itemprop="datePublished">2013-03-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/杂项/">杂项</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/03/01/Monty Hall problem/">有趣的三门问题（蒙提霍尔问题）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>三门问题（Monty Hall problem），是一个源自博弈论的数学游戏问题，大致出自美国的电视游戏节目Let’s Make a Deal。问题的名字来自该节目的主持人蒙提·霍尔（Monty Hall）。问题非常的有意思^_^，给出叙述如下：</p>
<p>在三扇门中的某扇门以后有一个奖品，选中这扇门就能拿到门后的奖品。你选定了一扇门，具体地说，假设你选择了1号门。这时候主持人蒙提·霍尔会打开剩下两扇门的其中一扇，你看到门后没有奖品。这时候他给你一个机会选择要不要换另外一扇没有打开的门。你是选择换还是不换呢？</p>
<p>答：因为我之前就选了，换或者不换机会都是均等的，所以换不换无关紧要╮(╯▽╰)╭。 ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ 真的是这样么？仔细分析一下，游戏过程中你做了2个操作： 第一，你选择了一扇门。第二，你选择了换门或者不换。 定义事件<span class="math inline">\(A\)</span>为你第一次就选中奖品。 定义事件<span class="math inline">\(B\)</span>为你换门选中奖品。 那么<span class="math inline">\(A^c\)</span>为集合A的余集，即第一次没有选中奖品。同理，<span class="math inline">\(B^c\)</span>为换门没有选中奖品。整个游戏过程中，<span class="math inline">\(A\)</span>或<span class="math inline">\(A^c\)</span>先发生，<span class="math inline">\(B\)</span>或<span class="math inline">\(B^c\)</span>再发生。 显而易见的是 <span class="math display">\[P(A)=1/3,P(A^c)=2/3\]</span> 要注意的是，在第一次操作之后，还有一件事——主持人打开了一扇没有奖品的门。值得注意的是，这里主持人的动作是跟你第一次选择有关系的：</p>
<ol style="list-style-type: decimal">
<li><p>如果你一开始就选中了奖品，即事件<span class="math inline">\(A\)</span>发生了，那么他就在剩下的两扇没有奖品的门之间任选一门打开。接下来，如果你选择换门，那么抽中的概率为0，不换抽中的概率为1。 即 <span class="math display">\[P(B|A)=0,P(B^c|A)=1\]</span> 因为事件<span class="math inline">\(B\)</span>或<span class="math inline">\(B^c\)</span>是在事件A发生之后发生的，所以这里的概率是基于事件<span class="math inline">\(A\)</span>的条件概率。</p></li>
<li><p>如果你开始没有选中奖品，即事件<span class="math inline">\(A^c\)</span>发生了，那么他只能打开另一扇没有奖品的门。这时候，如果你选择换门，那么抽中的概率为1，不换抽中的概率为0。 即 <span class="math display">\[P(B|A^c)=1,P(B^c|A^c)=0\]</span> 这里的概率是基于事件<span class="math inline">\(A^c\)</span>的条件概率。</p></li>
</ol>
<p>由上我们可以发现一点，事件<span class="math inline">\(A\)</span>会影响事件<span class="math inline">\(B\)</span>的概率，即事件<span class="math inline">\(A\)</span>和事件<span class="math inline">\(B\)</span>并不是相互独立的。<span class="math inline">\(A^c\)</span>和<span class="math inline">\(B^c\)</span>也是同理。 于是，利用全概率公式，我们可以求得换门选中奖品的概率为 <span class="math display">\[P(B)=P(B|A)P(A)+P(B|A^c)P(A^c)=0*1/3+1*2/3=2/3\]</span> <span class="math display">\[P(B^c)=P(B^c|A)P(A)+P(B^c|A^c)P(A^c)=1*1/3+0*2/3=1/3\]</span> 所以事实上你换门能得到奖品的概率为2/3，是不换门的2倍<del>（懂点数学真好啊）</del>。是不是和直觉不太一样？个人认为，直观上觉得<span class="math inline">\(P(B)=1/2\)</span>的原因是忽略了第一次选择时，通过主持人的动作改变了换门的事件概率这一客观过程。 <span style="color: #ff0000;">2013年7月3日更新</span><br>
从信息论的角度来说，B事件的熵为H(B)，在A事件发生之后B事件的条件熵为H(B|A)，可以证明 <span class="math display">\[H(B) \geq H(B|A) \]</span> 也就是说，在给予了A的信息之后，B的不确定性下降了。</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/03/01/Monty Hall problem/" data-id="cizha1qzt000wg0o8mebztao7" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/03/01/Monty Hall problem/#ds-thread" class="article-comment-link">Comments</a>
      

      
    </footer>
  </div>
  
</article>




  
    <article id="post-《数据挖掘导论》总结之聚类篇" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/02/21/《数据挖掘导论》总结之聚类篇/" class="article-date">
  <time datetime="2013-02-20T23:55:10.000Z" itemprop="datePublished">2013-02-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/02/21/《数据挖掘导论》总结之聚类篇/">《数据挖掘导论》总结之聚类篇</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>聚类分析将数据划分成有意义的簇，如果目标是划分成有意义的组，则簇应当捕获数据的自然结构。 聚类的目的可以分为2类：</p>
<ol style="list-style-type: decimal">
<li><p>旨在理解的聚类。比如生物学，信息检索，气候模式，心理学和医学，商业等。</p></li>
<li><p>旨在实用的聚类。旨在汇总数据，压缩数据，有效地发现最近邻。</p></li>
</ol>
        
          <p class="article-more-link">
            <a href="/2013/02/21/《数据挖掘导论》总结之聚类篇/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/02/21/《数据挖掘导论》总结之聚类篇/" data-id="cizha1qzp000pg0o8p0zifmot" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/02/21/《数据挖掘导论》总结之聚类篇/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-《数据挖掘导论》总结之关联分析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/02/18/《数据挖掘导论》总结之关联分析/" class="article-date">
  <time datetime="2013-02-18T00:33:19.000Z" itemprop="datePublished">2013-02-18</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/02/18/《数据挖掘导论》总结之关联分析/">《数据挖掘导论》总结之关联分析</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>关联分析是一种发现隐藏在大型数据集中有意义的数据联系的方法。所发现的联系可以用关联规则或者频繁项集的形式表示,比如以下规则： <span class="math display">\[\{nappy\}\rightarrow\{beer\}\]</span> 该规则表明尿布和啤酒的销售之间存在很强的联系，因为许多购买尿布的顾客也买啤酒。
        
          <p class="article-more-link">
            <a href="/2013/02/18/《数据挖掘导论》总结之关联分析/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/02/18/《数据挖掘导论》总结之关联分析/" data-id="cizha1qzn000kg0o8u8wawsvh" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/02/18/《数据挖掘导论》总结之关联分析/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li></ul>

    </footer>
  </div>
  
</article>




  
    <article id="post-《数据挖掘导论》总结之分类篇" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2013/01/14/《数据挖掘导论》总结之分类篇/" class="article-date">
  <time datetime="2013-01-13T22:46:13.000Z" itemprop="datePublished">2013-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/学术/">学术</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2013/01/14/《数据挖掘导论》总结之分类篇/">《数据挖掘导论》总结之分类篇</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="分类定义">分类定义</h1>
<p>分类任务就是通过学习得到一个目标函数(target function)<span class="math inline">\(f\)</span>,把每个属性集<span class="math inline">\(x\)</span>映射到一个预先定义的类标号<span class="math inline">\(y\)</span>。 分类和回归的区别之处就是类标号是否是离散的。回归的目标属性<span class="math inline">\(y\)</span>是连续的。 分类的一般方法有决策树，基于规则的分类，神经网络，支持向量机和朴素贝叶斯算法。</p>
<p>（改动中-2014年1月24日）
        
          <p class="article-more-link">
            <a href="/2013/01/14/《数据挖掘导论》总结之分类篇/#more">Read More</a>
          </p>
        
      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://crescentluna.github.io/2013/01/14/《数据挖掘导论》总结之分类篇/" data-id="cizha1qzr000ug0o8dpo89ngl" class="article-share-link" data-share="baidu">分享到</a>
      

      
        <a href="http://crescentluna.github.io/2013/01/14/《数据挖掘导论》总结之分类篇/#ds-thread" class="article-comment-link">Comments</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kNN/">kNN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/决策树/">决策树</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/贝叶斯方法/">贝叶斯方法</a></li></ul>

    </footer>
  </div>
  
</article>




  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/archives/2013/">&laquo; Prev</a><a class="page-number" href="/archives/2013/">1</a><span class="page-number current">2</span>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/学术/">学术</a><span class="category-list-count">18</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/学术/Gibbs-Sampling笔记/">Gibbs Sampling笔记</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/学术/变分推断笔记/">变分推断笔记</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂项/">杂项</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/杂项/闲话/">闲话</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/DP/" style="font-size: 13.33px;">DP</a> <a href="/tags/EM/" style="font-size: 20px;">EM</a> <a href="/tags/Gibbs-Sampling/" style="font-size: 20px;">Gibbs Sampling</a> <a href="/tags/Hexo/" style="font-size: 13.33px;">Hexo</a> <a href="/tags/LDA/" style="font-size: 10px;">LDA</a> <a href="/tags/PRML/" style="font-size: 13.33px;">PRML</a> <a href="/tags/Variational-Inference/" style="font-size: 16.67px;">Variational Inference</a> <a href="/tags/kNN/" style="font-size: 10px;">kNN</a> <a href="/tags/matlab/" style="font-size: 10px;">matlab</a> <a href="/tags/tensorflow/" style="font-size: 10px;">tensorflow</a> <a href="/tags/wordpress/" style="font-size: 10px;">wordpress</a> <a href="/tags/二叉树/" style="font-size: 10px;">二叉树</a> <a href="/tags/决策树/" style="font-size: 10px;">决策树</a> <a href="/tags/动态规划/" style="font-size: 10px;">动态规划</a> <a href="/tags/参数估计/" style="font-size: 10px;">参数估计</a> <a href="/tags/多项式分布/" style="font-size: 10px;">多项式分布</a> <a href="/tags/数据挖掘/" style="font-size: 16.67px;">数据挖掘</a> <a href="/tags/机器学习/" style="font-size: 16.67px;">机器学习</a> <a href="/tags/概率图/" style="font-size: 10px;">概率图</a> <a href="/tags/盘子/" style="font-size: 10px;">盘子</a> <a href="/tags/社区发现/" style="font-size: 10px;">社区发现</a> <a href="/tags/背包问题/" style="font-size: 13.33px;">背包问题</a> <a href="/tags/贝叶斯方法/" style="font-size: 10px;">贝叶斯方法</a> <a href="/tags/高斯混合模型/" style="font-size: 16.67px;">高斯混合模型</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">二月 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">十二月 2014</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/02/">二月 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/10/">十月 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/08/">八月 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/07/">七月 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/06/">六月 2013</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/04/">四月 2013</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/03/">三月 2013</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/02/">二月 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/01/">一月 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/12/">十二月 2012</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/10/">十月 2012</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/09/">九月 2012</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">浏览数目</h3>
    <div class="widget">
      <ul class="popularlist">
      </ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">近期文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/02/23/install-tensorflow-with-gpu-support-for-ubuntu/">在Ubuntu上搭建GPU加速的TensorFlow环境</a>
          </li>
        
          <li>
            <a href="/2014/12/12/variational-inference-3/">变分推断学习笔记(3)——三硬币问题的变分推断解法</a>
          </li>
        
          <li>
            <a href="/2014/12/11/popular-widget/">使用LeanCloud平台为Hexo博客添加文章浏览量统计组件</a>
          </li>
        
          <li>
            <a href="/2014/12/11/relocation/">博客迁移小记</a>
          </li>
        
          <li>
            <a href="/2014/02/24/概率图模型简介/">概率图模型简介</a>
          </li>
        
      </ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
  <h3 class="widget-title">最近评论</h3>
  <ul class="widget ds-recent-comments" data-num-items="5" data-show-avatars="0" data-show-title="1" data-show-time="1"></ul>
</div>
<!-- 需要多说的公用代码 -->


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://github.com/xiangming/landscape-plus" target="_blank">landscape-plus主题</a>
          </li>
        
          <li>
            <a href="http://www.smallqiao.com/" target="_blank">小桥流水</a>
          </li>
        
          <li>
            <a href="http://www.ahathinking.com/" target="_blank">勇幸|Thinking</a>
          </li>
        
          <li>
            <a href="http://www.socona.me/" target="_blank">socona的博客</a>
          </li>
        
          <li>
            <a href="http://www.clarkchen.com/" target="_blank">陈曦师兄的博客</a>
          </li>
        
          <li>
            <a href="http://www.fengyafei.com/" target="_blank">小飞的博客</a>
          </li>
        
          <li>
            <a href="http://ariwaranosai.xyz/" target="_blank">今天拒绝负能量!</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Chen Hao<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/xiangming/landscape-plus" target="_blank">Landscape-plus</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">主页</a>
  
    <a href="/archives" class="mobile-nav-link">所有文章</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    
<!-- 多说公共js代码 start -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"crescent"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
<!-- 多说公共js代码 end -->


<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>window._bd_share_config={"common":{},"share":{"bdCustomStyle":"nocss.css"}};with(document)0[(getElementsByTagName("head")[0]||body).appendChild(createElement("script")).src="http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion="+~(-new Date()/36e5)];</script>

<!-- 百度分享 end -->

<script src="//libs.baidu.com/jquery/1.11.1/jquery.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<! -- mathjax config similar to math.stackexchange -->
<! -- add autoNumber settting -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true
                    
}
  
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                  
}
    
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
            for(i=0; i < all.length; i += 1) {
                            all[i].SourceElement().parentNode.className += ' has-jax';
                                    
            }
                
        });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script src="/js/script.js"></script>

<!--page counter part-->
<script>
function addCount (Counter) {
        url=$('.article-date').attr('href').trim();
        title = $('.article-title').text().trim();
       // alert(title);
        var query=new AV.Query(Counter);
        //use url as unique idnetfication
        query.equalTo("url",url);
        query.find({
            success: function(results){
                if(results.length>0)
                {
                    var counter=results[0];
                    counter.fetchWhenSave(true); //get recent result
                    counter.increment("time");
                    counter.save();
                    //alert('find '+title+' and visit time is now '+ counter.get("time"));
                }
                else
                {
                    var newcounter=new Counter();
                    newcounter.set("title",title);
                    newcounter.set("url",url);
                    newcounter.set("time",1);
                    newcounter.save(null,{
                        success: function(newcounter){
                        //alert('New object created');
                        },
                        error: function(newcounter,error){
                        alert('Failed to create');
                        }
                        });
                }
            },
            error: function(error){
                //find null is not a error
                alert('Error:'+error.code+" "+error.message);
            }
        });
}

$(function(){
        var Counter=AV.Object.extend("Counter");
        //only increse visit counting when intering a page
        if ($('.article-title').length == 1)
           addCount(Counter);
        var query=new AV.Query(Counter);
        query.descending("time");
        query.limit(10);
        query.find({
            success: function(results){
                    for(var i=0;i<results.length;i++)    
                    {
                        var counter=results[i];
                        //alert(counter.get("title")+'-'+counter.get("url"));
                        title=counter.get("title");
                        url=counter.get("url");
                        time=counter.get("time");
                        // add to the popularlist widget
                        showcontent=title+" ("+time+")";
                        //notice the "" in href
                        $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                    }
                },
            error: function(error){
                alert("Error:"+error.code+" "+error.message);
            }
            }
        )
        });
</script>


  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>